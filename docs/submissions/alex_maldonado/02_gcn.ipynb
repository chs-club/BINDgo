{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Graph convolutional network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and processing\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "PATH_TRAIN_DATA = \"../../../data/train.parquet\"\n",
    "PATH_TEST_DATA = \"../../../data/test.parquet\"\n",
    "DATA = ds.dataset(source=PATH_TRAIN_DATA, format=\"parquet\")\n",
    "DATA_TEST = ds.dataset(source=PATH_TEST_DATA, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n_rows, train_split: float = 0.8) -> (npt.NDArray[np.uint64], npt.NDArray[np.uint64]):\n",
    "    # Generate indices and shuffle them in place\n",
    "    indices = np.arange(n_rows)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split indices into training and validation sets\n",
    "    train_size = int(n_rows * train_split)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    return train_indices, val_indices\n",
    "\n",
    "N_NO_BIND = 293656924\n",
    "N_BIND = 1589906\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "train_indices_no_bind, valid_indices_no_bind = split_indices(\n",
    "    N_NO_BIND, TRAIN_SPLIT\n",
    ")\n",
    "train_indices_bind, valid_indices_bind = split_indices(\n",
    "    N_BIND, TRAIN_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolDataset(Dataset):\n",
    "\n",
    "    protein_seq = {\n",
    "        \"sEH\": \"TLRAAVFDLDGVLALPAVFGVLGRTEEALALPRGLLNDAFQKGGPEGATTRLMKGEITLSQWIPLMEENCRKCSETAKVCLPKNFSIKEIFDKAISARKINRPMLQAALMLRKKGFTTAILTNTWLDDRAERDGLAQLMCELKMHFDFLIESCQVGMVKPEPQIYKFLLDTLKASPSEVVFLDDIGANLKPARDLGMVTILVQDTDTALKELEKVTGIQLLNTPAPLPTSCNPSDMSHGYVTVKPRVRLHFVELGSGPAVCLCHGFPESWYSWRYQIPALAQAGYRVLAMDMKGYGESSAPPEIEEYCMEVLCKEMVTFLDKLGLSQAVFIGHDWGGMLVWYMALFYPERVRAVASLNTPFIPANPNMSPLESIKANPVFDYQLYFQEPGVAEAELEQNLSRTFKSLFRASDESVLSMHKVCEAGGLFVNSPEEPSLSRMVTEEEIQFYVQQFKKSGFRGPLNWYRNMERNWKWACKSLGRKILIPALMVTAEKDFVLVPQMSQHMEDWIPHLKRGHIEDCGHWTQMDKPTEVNQILIKWLDSDARNPPVVSKM\",\n",
    "        \"BRD4\": \"NPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVDAVKLNLPDYYKIIKTPMDMGTIKKRLENNYYWNAQECIQDFNTMFTNCYIYNKPGDDIVLMAEALEKLFLQKINELPTEETEIMIVQAKGRGRGRKETGTAKPGVSTVPNTTQASTPPQTQTPQPNPPPVQATPHPFPAVTPDLIVQTPVMTVVPPQPLQTPPPVPPQPQPPPAPAPQPVQSHPPIIAATPQPVKTKKGVKRKADTTTPTTIDPIHEPPSLPPEPKTTKLGQRRESSRPVKPPKKDVPDSQQHPAPEKSSKVSEQLKCCSGILKEMFAKKHAAYAWPFYKPVDVEALGLHDYCDIIKHPMDMSTIKSKLEAREYRDAQEFGADVRLMFSNCYKYNPPDHEVVAMARKLQDVFEMRFAKMPDE\",\n",
    "        \"HSA\": \"DAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        scanner_no_bind,\n",
    "        scanner_bind,\n",
    "        indices_no_bind,\n",
    "        indices_bind,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.scanner_no_bind = scanner_no_bind\n",
    "        self.scanner_bind = scanner_bind\n",
    "        self.indices_no_bind = indices_no_bind\n",
    "        self.indices_bind = indices_bind\n",
    "\n",
    "    def get_protein_seq(self, key: str) -> str:\n",
    "        return self.protein_seq[key]\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_smiles(smiles: str) -> str:\n",
    "        smiles = smiles.replace(\"[Dy]\", \"\")\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            raise ValueError(\"Invalid SMILES string\")\n",
    "        mol = Chem.RemoveHs(mol)\n",
    "        fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "        largest_fragment = max(fragments, default=mol, key=lambda m: m.GetNumAtoms())\n",
    "        AllChem.Compute2DCoords(largest_fragment)\n",
    "        cleaned_smiles = Chem.MolToSmiles(largest_fragment, canonical=True)\n",
    "        return cleaned_smiles\n",
    "\n",
    "    @staticmethod\n",
    "    def get_mol(smiles: str) -> Chem.rdchem.Mol:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        mol = Chem.AddHs(mol)\n",
    "        AllChem.EmbedMolecule(mol)\n",
    "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
    "        return mol\n",
    "    \n",
    "    def get_sample(self, idx, kind):\n",
    "        if kind not in (\"bind\", \"no-bind\"):\n",
    "            raise ValueError(\"kind must be `bind` or `no-bind`\")\n",
    "        \n",
    "        record = None\n",
    "        if kind == \"bind\":\n",
    "            record = self.scanner_bind.take([idx]).to_pydict()\n",
    "        else:\n",
    "            record = self.scanner_no_bind.take([idx]).to_pydict()\n",
    "\n",
    "        smiles = record['molecule_smiles'][0]\n",
    "        protein_seq = record['protein_name'][0]\n",
    "        label = record['binds'][0]\n",
    "\n",
    "        smiles = self.clean_smiles(smiles)\n",
    "\n",
    "        amino_acids = self.get_protein_seq(protein_seq)\n",
    "        return smiles, amino_acids, label\n",
    "\n",
    "    def __getitem__(self, bind_idx: int) -> (str, str, int):\n",
    "        bind_data = self.get_sample(bind_idx, kind=\"bind\")\n",
    "        no_bind_idx = random.choice(self.indices_no_bind)\n",
    "        no_bind_data = self.get_sample(no_bind_idx, kind=\"no-bind\")\n",
    "        return bind_data, no_bind_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices_bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import mol_to_complete_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_atoms(mol):\n",
    "    feats = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_type = atom.GetAtomicNum()\n",
    "        degree = atom.GetDegree()\n",
    "        formal_charge = atom.GetFormalCharge()\n",
    "        hybridization = atom.GetHybridization()\n",
    "        is_aromatic = atom.GetIsAromatic()\n",
    "\n",
    "        if hybridization == Chem.HybridizationType.SP:\n",
    "            hybridization = 1\n",
    "        elif hybridization == Chem.HybridizationType.SP2:\n",
    "            hybridization = 2\n",
    "        elif hybridization == Chem.HybridizationType.SP3:\n",
    "            hybridization = 3\n",
    "        else:\n",
    "            hybridization = 0\n",
    "\n",
    "        feats.append([\n",
    "            atom_type,\n",
    "            degree,\n",
    "            formal_charge,\n",
    "            hybridization,\n",
    "            int(is_aromatic)\n",
    "        ])\n",
    "    return {'atomic': torch.tensor(feats).float()}\n",
    "\n",
    "def featurize_edges(mol, add_self_loop=False):\n",
    "    bond_types = {\n",
    "        Chem.BondType.SINGLE: 1,\n",
    "        Chem.BondType.DOUBLE: 2,\n",
    "        Chem.BondType.TRIPLE: 3,\n",
    "        Chem.BondType.AROMATIC: 4\n",
    "    }\n",
    "\n",
    "    src = []\n",
    "    dst = []\n",
    "    feats = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bond_type = bond_types.get(bond.GetBondType(), 0)\n",
    "        is_conjugated = bond.GetIsConjugated()\n",
    "        is_in_ring = bond.IsInRing()\n",
    "\n",
    "        src.append(i)\n",
    "        dst.append(j)\n",
    "        src.append(j)\n",
    "        dst.append(i)\n",
    "\n",
    "        feats.append([bond_type, int(is_conjugated), int(is_in_ring)])\n",
    "        feats.append([bond_type, int(is_conjugated), int(is_in_ring)])\n",
    "\n",
    "    if add_self_loop:\n",
    "        num_atoms = mol.GetNumAtoms()\n",
    "        for i in range(num_atoms):\n",
    "            src.append(i)\n",
    "            dst.append(i)\n",
    "            feats.append([0, 0, 0])\n",
    "\n",
    "    return {'src': torch.tensor(src).long(), 'dst': torch.tensor(dst).long(), 'bond': torch.tensor(feats).float()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    graphs_bind = []\n",
    "    graphs_no_bind = []\n",
    "    labels_bind = []\n",
    "    labels_no_bind = []\n",
    "    for item in batch:\n",
    "        if item is None:\n",
    "            continue\n",
    "        (smiles_bind, protein_seq_bind, label_bind), (smiles_no_bind, protein_seq_no_bind, label_no_bind) = item\n",
    "\n",
    "        try:\n",
    "            graph_bind = mol_to_complete_graph(\n",
    "                MolDataset.get_mol(smiles_bind),\n",
    "                node_featurizer=featurize_atoms,\n",
    "            )\n",
    "            graph_no_bind = mol_to_complete_graph(\n",
    "                MolDataset.get_mol(smiles_no_bind),\n",
    "                node_featurizer=featurize_atoms,\n",
    "            )\n",
    "\n",
    "            graphs_bind.append(graph_bind)\n",
    "            graphs_no_bind.append(graph_no_bind)\n",
    "            labels_bind.append(label_bind)\n",
    "            labels_no_bind.append(label_no_bind)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing molecule: {e}\")\n",
    "            continue\n",
    "\n",
    "    return dgl.batch(graphs_bind), torch.tensor(labels_bind), dgl.batch(graphs_no_bind), torch.tensor(labels_no_bind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner_no_bind = DATA.scanner(filter=(pc.field(\"binds\") == 0))\n",
    "scanner_bind = DATA.scanner(filter=(pc.field(\"binds\") == 1))\n",
    "\n",
    "train_data = MolDataset(scanner_no_bind, scanner_bind, train_indices_no_bind, train_indices_bind)\n",
    "valid_data = MolDataset(scanner_no_bind, scanner_bind, valid_indices_no_bind, valid_indices_bind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(valid_data, batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl.nn.pytorch import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, out_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = 5  # Number of features per atom\n",
    "h_feats = 16\n",
    "out_feats = 8  # Embedding dimension\n",
    "\n",
    "model = GCN(in_feats, h_feats, out_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(embeddings_bind, embeddings_no_bind, margin=1.0):\n",
    "    distance = torch.nn.functional.pairwise_distance(embeddings_bind, embeddings_no_bind)\n",
    "    loss = torch.mean((1 - labels) * torch.pow(distance, 2) + labels * torch.pow(torch.clamp(margin - distance, min=0.0), 2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/leash_bio_kaggle-dev/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        graphs_bind, labels_bind, graphs_no_bind, labels_no_bind = batch\n",
    "        \n",
    "        # Combine graphs and labels for binding and non-binding molecules\n",
    "        graphs = dgl.batch([graphs_bind, graphs_no_bind])\n",
    "        labels = torch.cat([labels_bind, labels_no_bind])\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings_bind = model(graphs_bind, graphs_bind.ndata['atomic'])\n",
    "        embeddings_no_bind = model(graphs_no_bind, graphs_no_bind.ndata['atomic'])\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = contrastive_loss(embeddings_bind, embeddings_no_bind)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosc1540-2024s-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
