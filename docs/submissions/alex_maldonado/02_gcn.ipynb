{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Graph convolutional network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and processing\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.dataset as ds\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "path_train_data = \"../../../data/train.parquet\"\n",
    "data = ds.dataset(source=path_train_data, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "\n",
    "    protein_seq = {\n",
    "        \"sEH\": \"TLRAAVFDLDGVLALPAVFGVLGRTEEALALPRGLLNDAFQKGGPEGATTRLMKGEITLSQWIPLMEENCRKCSETAKVCLPKNFSIKEIFDKAISARKINRPMLQAALMLRKKGFTTAILTNTWLDDRAERDGLAQLMCELKMHFDFLIESCQVGMVKPEPQIYKFLLDTLKASPSEVVFLDDIGANLKPARDLGMVTILVQDTDTALKELEKVTGIQLLNTPAPLPTSCNPSDMSHGYVTVKPRVRLHFVELGSGPAVCLCHGFPESWYSWRYQIPALAQAGYRVLAMDMKGYGESSAPPEIEEYCMEVLCKEMVTFLDKLGLSQAVFIGHDWGGMLVWYMALFYPERVRAVASLNTPFIPANPNMSPLESIKANPVFDYQLYFQEPGVAEAELEQNLSRTFKSLFRASDESVLSMHKVCEAGGLFVNSPEEPSLSRMVTEEEIQFYVQQFKKSGFRGPLNWYRNMERNWKWACKSLGRKILIPALMVTAEKDFVLVPQMSQHMEDWIPHLKRGHIEDCGHWTQMDKPTEVNQILIKWLDSDARNPPVVSKM\",\n",
    "        \"BRD4\": \"NPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVDAVKLNLPDYYKIIKTPMDMGTIKKRLENNYYWNAQECIQDFNTMFTNCYIYNKPGDDIVLMAEALEKLFLQKINELPTEETEIMIVQAKGRGRGRKETGTAKPGVSTVPNTTQASTPPQTQTPQPNPPPVQATPHPFPAVTPDLIVQTPVMTVVPPQPLQTPPPVPPQPQPPPAPAPQPVQSHPPIIAATPQPVKTKKGVKRKADTTTPTTIDPIHEPPSLPPEPKTTKLGQRRESSRPVKPPKKDVPDSQQHPAPEKSSKVSEQLKCCSGILKEMFAKKHAAYAWPFYKPVDVEALGLHDYCDIIKHPMDMSTIKSKLEAREYRDAQEFGADVRLMFSNCYKYNPPDHEVVAMARKLQDVFEMRFAKMPDE\",\n",
    "        \"HSA\": \"DAHKSEVAHRFKDLGEENFKALVLIAFAQYLQQCPFEDHVKLVNEVTEFAKTCVADESAENCDKSLHTLFGDKLCTVATLRETYGEMADCCAKQEPERNECFLQHKDDNPNLPRLVRPEVDVMCTAFHDNEETFLKKYLYEIARRHPYFYAPELLFFAKRYKAAFTECCQAADKAACLLPKLDELRDEGKASSAKQRLKCASLQKFGERAFKAWAVARLSQRFPKAEFAEVSKLVTDLTKVHTECCHGDLLECADDRADLAKYICENQDSISSKLKECCEKPLLEKSHCIAEVENDEMPADLPSLAADFVESKDVCKNYAEAKDVFLGMFLYEYARRHPDYSVVLLLRLAKTYETTLEKCCAAADPHECYAKVFDEFKPLVEEPQNLIKQNCELFEQLGEYKFQNALLVRYTKKVPQVSTPTLVEVSRNLGKVGSKCCKHPEAKRMPCAEDYLSVVLNQLCVLHEKTPVSDRVTKCCTESLVNRRPCFSALEVDETYVPKEFNAETFTFHADICTLSEKERQIKKQTALVELVKHKPKATKEQLKAVMDDFAAFVEKCCKADDKETCFAEEGKKLVAASQAALGL\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self, file_path: str, train_split: float = 0.8, *args, **kwargs\n",
    "    ) -> None:\n",
    "        self.data = ds.dataset(source=file_path, *args, **kwargs)\n",
    "        self.train_split = train_split\n",
    "        self.set_indices(train_split=train_split)\n",
    "    \n",
    "    def set_indices(\n",
    "        self,\n",
    "        n_no_bind: int = 293656924,\n",
    "        n_bind: int = 1589906,\n",
    "        train_split: float = 0.8\n",
    "    ) -> None:\n",
    "        self.train_indices_no_bind, self.valid_indices_no_bind = self._get_indices(\n",
    "            n_no_bind, train_split\n",
    "        )\n",
    "        self.train_indices_bind, self.valid_indices_bind = self._get_indices(\n",
    "            n_bind, train_split\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_indices(\n",
    "        n_rows, train_split: float = 0.8\n",
    "    ) -> (npt.NDArray[np.uint64], npt.NDArray[np.uint64]):\n",
    "        # Generate indices and shuffle them in place\n",
    "        indices = np.arange(n_rows)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        # Split indices into training and validation sets\n",
    "        train_size = int(n_rows * train_split)\n",
    "        train_indices = indices[:train_size]\n",
    "        val_indices = indices[train_size:]\n",
    "        return train_indices, val_indices\n",
    "\n",
    "    \n",
    "    def split_data(self, train_split: float = 0.8) -> None:\n",
    "        self.scanner_no_bind = self.data.scanner(\n",
    "            filter=(pc.field(\"binds\") == 0)\n",
    "        )\n",
    "        self.scanner_bind = self.data.scanner(\n",
    "            filter=(pc.field(\"binds\") == 1)\n",
    "        )\n",
    "\n",
    "    def get_protein_seq(self, key: str) -> str:\n",
    "        return self.protein_seq[key]\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_smiles(smiles: str) -> str:\n",
    "        smiles = smiles.replace(\"[Dy]\", \"\")\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            raise ValueError(\"Invalid SMILES string\")\n",
    "        mol = Chem.RemoveHs(mol)\n",
    "        fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "        largest_fragment = max(\n",
    "            fragments, default=mol, key=lambda m: m.GetNumAtoms()\n",
    "        )\n",
    "        AllChem.Compute2DCoords(largest_fragment)\n",
    "        cleaned_smiles = Chem.MolToSmiles(\n",
    "            largest_fragment, canonical=True\n",
    "        )\n",
    "        return cleaned_smiles\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_mol(smiles: str) -> Chem.rdchem.Mol:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        mol = Chem.AddHs(mol)\n",
    "        AllChem.EmbedMolecule(mol)\n",
    "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
    "        return mol\n",
    "    \n",
    "    def __getitem__(self, idx: int, kind: str = \"bind\") -> (str, str, int):\n",
    "\n",
    "        if kind not in (\"bind\", \"no-bind\"):\n",
    "            raise ValueError(\"kind must be `bind` or `no-bind`\")\n",
    "        \n",
    "        if kind == \"bind\":\n",
    "            record = self.scanner_bind[idx]\n",
    "        else:\n",
    "            record = self.scanner_no_bind[idx]\n",
    "        smiles: str = record['molecule_smiles'].as_py()\n",
    "        protein_seq: str = record['protein_name'].as_py()\n",
    "        label: int = record['binds'].as_py()\n",
    "\n",
    "        smiles = self.clean_smiles(smiles)\n",
    "        if smiles is None:\n",
    "            return None\n",
    "\n",
    "        amino_acids = self.get_protein_seq(protein_seq)\n",
    "        return smiles, amino_acids, label\n",
    "    \n",
    "    def get_contrastive_pair(self, idx: int) -> ((str, str, int), (str, str, int)):\n",
    "        no_bind_idx = random.choice(self.train_indices_no_bind)\n",
    "        bind_idx = random.choice(self.train_indices_bind)\n",
    "        no_bind_sample = self.__getitem__(no_bind_idx, kind=\"no-bind\")\n",
    "        bind_sample = self.__getitem__(bind_idx, kind=\"bind\")\n",
    "        return no_bind_sample, bind_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# # See https://github.com/pytorch/pytorch/pull/122616#issuecomment-2100569173\n",
    "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
    "\n",
    "import dgl\n",
    "from dgl.nn.pytorch import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph neural network\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, h_feats)\n",
    "        self.classify = nn.Linear(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        hg = dgl.mean_nodes(g, 'h')\n",
    "        return self.classify(hg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosc1540-2024s-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
